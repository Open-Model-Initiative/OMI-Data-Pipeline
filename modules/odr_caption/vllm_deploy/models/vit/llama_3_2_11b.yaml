# Docker configuration
docker:
  port: 12434:8000
  options: --ipc=host
  image: vllm/vllm-openai:latest

# vLLM configuration
vllm:
  max_model_len: 16384
  model: unsloth/Llama-3.2-11B-Vision-Instruct
  enforce-eager: true
  max-num-seqs: 8
  limit-mm-per-prompt: 'image=1'
  max-model-len: 2048
