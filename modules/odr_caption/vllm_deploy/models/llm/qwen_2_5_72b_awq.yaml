# Docker configuration
docker:
  port: 12434:8000
  options: --ipc=host
  image: vllm/vllm-openai:latest

# vLLM configuration
vllm:
  model: Qwen/Qwen2.5-72B-Instruct-AWQ
  quantization: awq
  max_model_len: 5152
