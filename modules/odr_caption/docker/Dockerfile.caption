FROM vllm/vllm-openai:v0.6.4.post1

# Create a non-root user and set up cache directory
RUN groupadd -r appuser && useradd -r -g appuser appuser \
    && mkdir -p /home/appuser/.cache \
    && chown -R appuser:appuser /home/appuser

ENV VLLM_VERSION=v0.6.4.post1
ENV DO_NOT_TRACK=1

# Install dependencies
COPY ./requirements.txt /app/requirements.txt

# Copy application code
COPY . /app
RUN pip3 install --no-cache-dir -e /app \
    && pip3 install git+https://github.com/dottxt-ai/outlines --upgrade \
    && chown -R appuser:appuser /app \
    && mkdir -p /vllm-workspace \
    && chown -R appuser:appuser /vllm-workspace

# Set Python path to include the modules
ENV PYTHONPATH=/app:/app/modules:$PYTHONPATH

# Set cache directory environment variable
ENV TRANSFORMERS_CACHE=/vllm-workspace/cache

# Expose the port the app runs on
EXPOSE 32100

COPY --chmod=775 endpoints-entrypoint.sh entrypoint.sh
RUN chown appuser:appuser entrypoint.sh

# Switch to non-root user
USER appuser

ENTRYPOINT ["/bin/bash", "entrypoint.sh"]
CMD ["tail", "-f", "/dev/null"]
